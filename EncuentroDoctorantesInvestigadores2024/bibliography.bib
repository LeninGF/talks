@inproceedings{LGFalconi2019,
	title        = {Transfer Learning in Breast Mammogram Abnormalities Classification With Mobilenet and Nasnet},
	author       = {L. G. {Falconí} and M. {Pérez} and W. G. {Aguilar}},
	year         = 2019,
	month        = {June},
	booktitle    = {2019 International Conference on Systems, Signals and Image Processing (IWSSIP)},
	volume       = {},
	number       = {},
	pages        = {109--114},
	doi          = {10.1109/IWSSIP.2019.8787295},
	issn         = {2157-8702},
	keywords     = {cancer;image classification;learning (artificial intelligence);mammography;medical image processing;transfer learning;breast mammogram abnormalities classification;breast cancer;women mortality worldwide;malignancy classification;artificial intelligence;deep learning models;computer aided diagnosis systems;CADx;image pre-processing;Mammography;Feature extraction;Training;Cancer;Deep learning;Solid modeling;Breast;deep learning;digital mammogram;image pre-processing;machine learning;transfer learning}
}

@article{Falconi2020,
	title        = {{Transfer learning and fine tuning in breast mammogram abnormalities classification on CBIS-DDSM database}},
	author       = {Lenin G. Falcon\'{i} and Maria P\'{e}rez and Wilbert G. Aguilar and Aura Conci},
	year         = 2020,
	journal      = {Advances in Science, Technology and Engineering Systems},
	volume       = 5,
	number       = 2,
	pages        = {154--165},
	doi          = {10.25046/aj050220},
	issn         = 24156698,
	abstract     = {Breast cancer has an important incidence in women mortality worldwide. Currently, mam-mography is considered the gold standard for breast abnormalities screening examinations, since it aids in the early detection and diagnosis of the illness. However, both identification of mass lesions and its malignancy classification is a challenging problem for artificial intelligence. In this work, we extend our previous research in mammogram classification, where we studied NasNet and MobileNet in transfer learning to train a breast abnormality malignancy classifier, and include models like: VGG, Resnet, Xception and Resnext. However, training deep learning models tends to overfit. This problem is also carried out in this work. Our results show that Fine Tuning achieves the best classifier performance in VGG16 with AUC value of 0.844 in the CBIS-DDSM dataset.},
	file         = {:C$\backslash$:/Users/tanve/Downloads/ASTESJ{\_}050220.pdf:pdf},
	keywords     = {Convolutional neural networks,Fine tuning,Mammogram classification,Transfer learning}
}

@inproceedings{falconi2020transfer,
	title        = {Transfer learning and fine tuning in mammogram bi-rads classification},
	author       = {Falcon{\'\i}, Lenin and P{\'e}rez, Mar{\'\i}a and Aguilar, Wilbert and Conci, Aura},
	year         = 2020,
	booktitle    = {2020 IEEE 33rd International Symposium on computer-based medical systems (CBMS)},
	pages        = {475--480},
	organization = {IEEE}
}

@misc{sierrafranco2023segmentationmammo,
	title        = {Towards Automated Semantic Segmentation in Mammography Images},
	author       = {Cesar A. Sierra-Franco and Jan Hurtado and Victor de A. Thomaz and Leonardo C. da Cruz and Santiago V. Silva and Alberto B. Raposo},
	year         = 2023,
	url          = {https://arxiv.org/abs/2307.10296},
	eprint       = {2307.10296},
	archiveprefix = {arXiv},
	primaryclass = {eess.IV}
}

@article{carvalo2023Thermo,
	title        = {U-Net Convolutional Neural Networks for breast IR imaging segmentation on frontal and lateral view},
	author       = {Elisson Carlos de Carvalho, Alessandra Martins Coelho, Aura Conci and Matheus de Freitas Oliveira Baffa},
	year         = 2023,
	journal      = {Computer Methods in Biomechanics and Biomedical Engineering: Imaging \& Visualization},
	publisher    = {Taylor \& Francis},
	volume       = 11,
	number       = 3,
	pages        = {311--316},
	doi          = {10.1080/21681163.2022.2040053},
	url          = {https://doi.org/10.1080/21681163.2022.2040053},
	eprint       = {https://doi.org/10.1080/21681163.2022.2040053},
	abstract     = {Breast cancer is the leading type of cancer among women. According to the World Cancer Research Fund, in 2018, over 2 million new cases were detected around the world. Despite its high occurrence, early detection provides a better prognosis and helps increases the patient’s survival. Significant advances in screening techniques, such as infrared imaging, have provided a cheap and less invasive way to detect the disease. Besides, computational tools can be used to assist doctors in providing a better diagnosis. Therefore, this paper presents a segmentation method based on U-Net Convolutional Neural Networks. In contrast to the state-of-the-art, machine learning approaches have been shown to be efficient for ROI segmentation, reaching an accuracy of 98.24\% over the frontal view, and 93.6\% over the lateral view. This segmentation method may be very useful for classification tasks, once the region of interest is well delimited for feature extraction.}
}